package analyzer

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github-gold-miner/internal/domain"
	"github-gold-miner/internal/port"
)

// RepoAnalyzer å®ç°äº† port.Analyzer æ¥å£
type RepoAnalyzer struct {
	appraiser     port.Appraiser
	maxGoroutines int // æœ€å¤§å¹¶å‘æ•°
	nowFunc       func() time.Time
}

// NewRepoAnalyzer åˆ›å»ºæ–°çš„åˆ†æå™¨å®ä¾‹
func NewRepoAnalyzer(appraiser port.Appraiser) *RepoAnalyzer {
	return &RepoAnalyzer{
		appraiser:     appraiser,
		maxGoroutines: 3,        // é»˜è®¤å¹¶å‘æ•°ä¸º3
		nowFunc:       time.Now, // ä¾¿äºæµ‹è¯•æ³¨å…¥å½“å‰æ—¶é—´
	}
}

// SetMaxGoroutines è®¾ç½®æœ€å¤§å¹¶å‘æ•°
func (a *RepoAnalyzer) SetMaxGoroutines(max int) {
	if max > 0 {
		a.maxGoroutines = max
	}
}

// CalculateStarGrowthRate è®¡ç®—Starå¢é•¿ç‡
func (a *RepoAnalyzer) CalculateStarGrowthRate(repos []*domain.Repo) []*domain.Repo {
	current := time.Now()
	if a != nil && a.nowFunc != nil {
		current = a.nowFunc()
	}

	for _, repo := range repos {
		// è®¡ç®—é¡¹ç›®å­˜æ´»å¤©æ•°
		daysAlive := current.Sub(repo.CreatedAt).Hours() / 24
		if daysAlive <= 0 {
			repo.StarGrowthRate = 0
		} else {
			// è®¡ç®—æ¯æ—¥Starå¢é•¿é€Ÿç‡
			repo.StarGrowthRate = float64(repo.Stars) / daysAlive
		}
	}
	return repos
}

// analyzeRepoWorker å·¥ä½œåç¨‹ï¼Œå¤„ç†å•ä¸ªrepoçš„åˆ†æ
func (a *RepoAnalyzer) analyzeRepoWorker(
	ctx context.Context,
	jobs <-chan *domain.Repo,
	results chan<- *domain.Repo,
	errors chan<- error,
	wg *sync.WaitGroup,
	workerID int,
) {
	defer wg.Done()

	for repo := range jobs {
		fmt.Printf("   [Worker-%d] æ­£åœ¨åˆ†æ %s...\n", workerID, repo.Name)

		// ä¸ºæ¯ä¸ªé¡¹ç›®è®¾ç½®è¶…æ—¶æ—¶é—´(30ç§’)
		projectCtx, cancel := context.WithTimeout(ctx, 30*time.Second)

		// ä½¿ç”¨ç°æœ‰çš„Appraiserè¿›è¡Œåˆ†æ
		analyzedRepo, err := a.appraiser.Appraise(projectCtx, repo)
		cancel() // ç«‹å³é‡Šæ”¾èµ„æº

		if err != nil {
			// å¦‚æœåˆ†æå¤±è´¥ï¼Œè®°å½•é”™è¯¯
			fmt.Printf("   [Worker-%d] âŒ %s åˆ†æå¤±è´¥: %v\n", workerID, repo.Name, err)
			errors <- fmt.Errorf("åˆ†æ %s å¤±è´¥: %w", repo.Name, err)
			// å³ä½¿å¤±è´¥ä¹Ÿè¿”å›åŸå§‹repoï¼Œè¿™æ ·ä¸ä¼šé˜»å¡ä¸»æµç¨‹
			results <- repo
			continue
		}

		// æ›´æ–°repoä¿¡æ¯
		repo.IsAIProgrammingTool = analyzedRepo.IsAIProgrammingTool
		repo.LLMScore = analyzedRepo.LLMScore
		repo.LLMReview = analyzedRepo.LLMReview

		fmt.Printf("   [Worker-%d] âœ… %s åˆ†æå®Œæˆ (è¯„åˆ†: %d)\n", workerID, repo.Name, repo.LLMScore)
		results <- repo
	}
}

// AnalyzeWithLLM ä½¿ç”¨LLMå¹¶å‘åˆ†æé¡¹ç›®æ˜¯å¦ä¸ºAIç¼–ç¨‹å·¥å…·åŠå…¶è¯„åˆ†
func (a *RepoAnalyzer) AnalyzeWithLLM(ctx context.Context, repos []*domain.Repo) ([]*domain.Repo, error) {
	fmt.Printf("ğŸ¤– å¼€å§‹LLMåˆ†æï¼Œå…± %d ä¸ªé¡¹ç›®ï¼Œæœ€å¤§å¹¶å‘æ•°: %d\n", len(repos), a.maxGoroutines)

	// åˆ›å»ºchannelç”¨äºä¼ é€’jobså’Œresults
	jobs := make(chan *domain.Repo, len(repos))
	results := make(chan *domain.Repo, len(repos))
	errors := make(chan error, len(repos))

	// å¯åŠ¨workers
	var wg sync.WaitGroup
	for i := 0; i < a.maxGoroutines; i++ {
		wg.Add(1)
		go a.analyzeRepoWorker(ctx, jobs, results, errors, &wg, i+1)
	}

	// å‘é€jobs
	for _, repo := range repos {
		jobs <- repo
	}
	close(jobs)

	// ç­‰å¾…æ‰€æœ‰workerså®Œæˆ
	done := make(chan struct{})
	go func() {
		wg.Wait()
		close(done)
	}()

	// ç­‰å¾…å®Œæˆæˆ–è¶…æ—¶
	select {
	case <-done:
		// æ‰€æœ‰ä»»åŠ¡å®Œæˆ
	case <-ctx.Done():
		// ä¸Šä¸‹æ–‡è¶…æ—¶æˆ–å–æ¶ˆ
		fmt.Println("â° LLMåˆ†æå› è¶…æ—¶æˆ–å–æ¶ˆè€Œä¸­æ–­")
		return repos, ctx.Err()
	}

	// å…³é—­channels
	close(results)
	close(errors)

	// æ”¶é›†ç»“æœ
	analyzedRepos := make([]*domain.Repo, 0, len(repos))
	for result := range results {
		analyzedRepos = append(analyzedRepos, result)
	}

	// æ‰“å°é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
	if len(errors) > 0 {
		fmt.Printf("âš ï¸  å…±æœ‰ %d ä¸ªåˆ†æé”™è¯¯:\n", len(errors))
		for err := range errors {
			fmt.Printf("   é”™è¯¯: %v\n", err)
		}
	}

	fmt.Println("âœ… LLMåˆ†æå®Œæˆ")
	return analyzedRepos, nil
}
